Bem vindo

Este projeto mostra o passo a passo real da an√°lise de dados de um conjunto de vendas, desde a limpeza no Python at√© a modelagem SQL e visualiza√ß√£o no Power BI.

O foco foi extrair insights como **√∫ltima compra por cliente e produto**, **ticket m√©dio**, **produtos mais impactantes**, e **frequ√™ncia de compra**.

---

## ‚úçÔ∏è Di√°rio Pessoal de Execu√ß√£o

Criei a base das necessidades e busquei as solu√ß√µes com as linguagens de conhecimento come√ßando pelo Python.

1. Salvei um conjunto de dados de Vendas pelo site Kaggle.com  
2. Importei algumas APIs de costume: `"numpy"`, `"pandas"` e criei a conex√£o com as tabelas.  
3. Ap√≥s importar os arquivos `.csv` com o pandas, conferi os dados com `head()` e verifiquei os tipos de codifica√ß√£o pra evitar erro de leitura ‚Äî principalmente com acentua√ß√£o, como foi o caso das tabelas `stores_df` e `hubs_df`, que utilizei o par√¢metro `encoding='ISO-8859-1'`, a alternativa que solucionou isso.  
4. Explorei os dados com `df.head()` e percebi colunas com nomes longos ou com espa√ßos, o que poderia dificultar a manipula√ß√£o. Anotei isso para padronizar depois, se necess√°rio.  
5. Usei `df.info()` e notei colunas sendo tratadas como `object`, mesmo sendo num√©ricas ‚Äî tratei isso logo para evitar erro mais √† frente.  
6. Identifiquei valores nulos com `df.isnull().sum()` e fiz uma ‚Äúcharadinha false‚Äù pra priorizar as colunas que realmente precisavam de tratamento.  
7. Para poucos valores nulos: preenchi com `.fillna(df['coluna'].mode()[0])` ou mediana para num√©ricos.  
8. Alguns campos como localiza√ß√£o ou c√≥digo da loja ficaram nulos por escolha, pois a aus√™ncia indicava erro ‚Äî mantive nulo pra n√£o comprometer.  
9. Salvei tudo em um `DataFrame` limpo e documentei cada modifica√ß√£o pra rastreabilidade.  
10. Salvei uma vers√£o intermedi√°ria com `to_csv('store_limpo.csv', index=False)` pra n√£o comprometer os dados brutos.  
11. Criei um loop para detectar colunas `object` que podiam ser datas mascaradas. Usei `pd.to_datetime(errors='coerce')` e se 80% convertesse, marcava como ‚Äúsuspeita‚Äù.  
12. Criei a fun√ß√£o `LIMPAR_TEXTO()` que padroniza textos: remove acento, coloca em min√∫sculo e tira espa√ßo extra.  
13. Para datas com formatos estranhos (ex: ‚Äú04/30/2021 9:59:57 AM‚Äù), usei regex e `pd.to_datetime()` ap√≥s teste com amostras.  
14. Para campos num√©ricos como texto, tirei v√≠rgulas, usei `pd.to_numeric(errors='ignore')`, e validei com `is_numeric_dtype()`.  
15. Depois de limpar tudo, preparei um banco em mem√≥ria com `sqlite3`. Adicionei `DROP TABLE` e `DROP VIEW` pra deixar tudo limpo e isolado.  
16. Meu projeto se baseia nas linguagens que mais estudo: Python e SQL, com foco em an√°lise.  
17. Comecei criando as tabelas `clientes`, `produtos`, `vendas`.  
18. `clientes` tinha `id_cliente`, `nome`, `email`. Em `produtos`, coloquei `id_produto`, `nome`, `categoria`, `pre√ßo` (tipo REAL).  
19. Em `vendas`, relacionei os IDs e inclu√≠ `quantidade`, `data`. A data ficou como `TEXT` no formato `yyyy/mm/dd` para compatibilidade com SQLite.  
20. A modelagem ficou simples e funcional, permitindo consultas como: receita por cliente, produtos mais vendidos, frequ√™ncia, etc.  
21. Criei as primeiras consultas SQL com `SELECT` + `JOIN` para buscar vendas por cliente e produto.  
22. Notei lentid√£o e erros em algumas queries. Resolvi criando √≠ndices nas colunas `id_cliente` e `id_produto`.  
23. Validei os totais comparando com os dados no Python, conferindo se a modelagem estava certa.  
24. Comecei a analisar frequ√™ncia de compra por cliente com `GROUP BY`, `COUNT` e `SUM`.  
25. Fiz testes para separar clientes recorrentes de novos com base na data da primeira compra.  
26. Calculei o **ticket m√©dio** por cliente: total gasto √∑ n√∫mero de compras.  
27. Tratei o caso de clientes com uma √∫nica compra pra n√£o distorcer as m√©dias.  
28. Documentei todas as queries com coment√°rios, pra facilitar a leitura e reuso.  
29. Comecei a desenhar os gr√°ficos e m√©tricas mais √∫teis pro neg√≥cio.  
30. Exportei os resultados das queries para `.csv` e levei para o Power BI.

---

## üìä An√°lise: √öltima Compra por Cliente e Produto

| Cliente   | Produto   | Data       | Quantidade | Pre√ßo     | Valor Total |
|-----------|-----------|------------|------------|-----------|-------------|
| Cliente A | Produto X | 2023-01-25 | 2          | R$ 550,00 | R$ 1100,00  |
| Cliente A | Produto Y | 2023-01-20 | 5          | R$ 45,00  | R$ 225,00   |
| Cliente B | Produto Z | 2023-02-10 | 1          | R$ 1200,00| R$ 1200,00  |
| Cliente C | Produto W | 2023-03-05 | 3          | R$ 30,00  | R$ 90,00    |

---

### üéüÔ∏è Ticket M√©dio por Cliente

| Cliente   | Ticket M√©dio |
|-----------|--------------|
| Cliente A | R$ 662,50    |
| Cliente B | R$ 630,00    |
| Cliente C | R$ 95,00     |

---

## üß© Conclus√µes Estrat√©gicas

### 1. Quais clientes geram mais receita por compra?
- **Cliente A e Cliente B** s√£o os que mais gastam por compra.
- Ideal para campanhas de reten√ß√£o e **fideliza√ß√£o**.
- Cliente C √© mais econ√¥mico, indicado para **combos promocionais**.

### 2. Quais produtos mais impactam o ticket m√©dio?
- **Produto X** e **Produto Z** t√™m maior peso no ticket m√©dio.
- Devem ser destacados com estrat√©gias que aumentem **valor percebido**.

### 3. Quais produtos os clientes compram com mais frequ√™ncia?
- Produtos como **Produto W** e **Produto Y** aparecem com mais recorr√™ncia.
- Potencial para **programas de fidelidade** e **vendas cruzadas**.

---

## ‚ö° Tecnologias Utilizadas

- Python (Pandas, NumPy)
- SQLite3 (banco de dados em mem√≥ria)
- SQL puro para modelagem e extra√ß√£o
- Power BI para visualiza√ß√£o de insights

---

## üôå Sobre Mim

 An√°lise e Desenvolvimento de Sistemas ,sou apaixonada por dados. Esse projeto reflete n√£o s√≥ meus conhecimentos t√©cnicos em Python, SQL , mas tamb√©m minha **dedica√ß√£o, resili√™ncia e vontade de aprender na pr√°tica ,a ser uma analista de dados.**.

---

